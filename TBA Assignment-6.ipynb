{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69f39cd",
   "metadata": {},
   "source": [
    "# CS-651-A TEXT BASED ANALYSIS\n",
    "# Sai Vandana - 0939231\n",
    "# Assignment - 6 5/4/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ca0b9",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8637e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb14ae",
   "metadata": {},
   "source": [
    "#### The code reads text from a file, splits it into sentences, cleans each sentence by removing non-alphabetical characters, splits them into words, and prints both the original and cleaned versions of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4407253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: In the heart of an ancient forest, a mysterious and untouched land hides secrets of the ages\n",
      "Processed: ['In', 'the', 'heart', 'of', 'an', 'ancient', 'forest', 'a', 'mysterious', 'and', 'untouched', 'land', 'hides', 'secrets', 'of', 'the', 'ages']\n",
      "Original: This forest, known only to the old wise owl and the creatures that inhabit its dark recesses, holds the key to a magical world where time stands still and nature speaks\n",
      "Processed: ['This', 'forest', 'known', 'only', 'to', 'the', 'old', 'wise', 'owl', 'and', 'the', 'creatures', 'that', 'inhabit', 'its', 'dark', 'recesses', 'holds', 'the', 'key', 'to', 'a', 'magical', 'world', 'where', 'time', 'stands', 'still', 'and', 'nature', 'speaks']\n"
     ]
    }
   ],
   "source": [
    "import re  # Import regular expressions to handle non-alphabetical removal\n",
    "\n",
    "# Open the file with appropriate encoding\n",
    "file = open(\"EnglishText.txt\", \"r\", encoding='utf-8')\n",
    "# Read all lines from the file\n",
    "filedata = file.read()  # Changed to read() to handle multiple lines if necessary\n",
    "# Split into sentences by period followed by a space or at the end of paragraphs\n",
    "article = re.split(r'\\.\\s+|\\.$', filedata.strip())\n",
    "\n",
    "sentences = []\n",
    "# Iterate over each sentence in the article\n",
    "for sentence in article:\n",
    "    # Check if the sentence is not just whitespace\n",
    "    if sentence.strip():\n",
    "        # Print the original sentence\n",
    "        print(\"Original:\", sentence)\n",
    "        # Clean the sentence by removing non-alphabetical characters, then split into words\n",
    "        cleaned_sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence).split()\n",
    "        # Append the cleaned words of the sentence to the list\n",
    "        sentences.append(cleaned_sentence)\n",
    "        # Print the cleaned and split sentence\n",
    "        print(\"Processed:\", cleaned_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a73b0",
   "metadata": {},
   "source": [
    "#### The code reads text from a file, splits it into Spanish sentences using appropriate punctuation, cleans each sentence by removing non-alphabetical characters (preserving Spanish accents and ñ), splits them into words, and prints both the original and cleaned versions of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d47c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: En el corazón de un bosque antiguo, una tierra misteriosa e intacta esconde secretos de los tiempos.\n",
      "Processed: ['En', 'el', 'corazón', 'de', 'un', 'bosque', 'antiguo', 'una', 'tierra', 'misteriosa', 'e', 'intacta', 'esconde', 'secretos', 'de', 'los', 'tiempos']\n",
      "Original: Este bosque, conocido solo por el viejo búho sabio y las criaturas que habitan sus oscuros recovecos, guarda la llave de un mundo mágico donde el tiempo se detiene y la naturaleza habla.\n",
      "Processed: ['Este', 'bosque', 'conocido', 'solo', 'por', 'el', 'viejo', 'búho', 'sabio', 'y', 'las', 'criaturas', 'que', 'habitan', 'sus', 'oscuros', 'recovecos', 'guarda', 'la', 'llave', 'de', 'un', 'mundo', 'mágico', 'donde', 'el', 'tiempo', 'se', 'detiene', 'y', 'la', 'naturaleza', 'habla']\n"
     ]
    }
   ],
   "source": [
    "import re  # Import regular expressions to handle non-alphabetical removal\n",
    "\n",
    "# Open the file with appropriate encoding\n",
    "file = open(\"SpanishText.txt\", \"r\", encoding='utf-8')\n",
    "# Read all lines from the file\n",
    "filedata = file.read()  # Changed to read() to handle multiple lines if necessary\n",
    "# Split into sentences considering Spanish punctuation\n",
    "article = re.split(r'(?<=[.!?¿¡])\\s+', filedata.strip())\n",
    "\n",
    "sentences = []\n",
    "# Iterate over each sentence in the article\n",
    "for sentence in article:\n",
    "    # Check if the sentence is not just whitespace\n",
    "    if sentence.strip():\n",
    "        # Print the original sentence\n",
    "        print(\"Original:\", sentence)\n",
    "        # Clean the sentence by removing non-alphabetical characters, then split into words\n",
    "        cleaned_sentence = re.sub(\"[^a-zA-ZáéíóúñÁÉÍÓÚÑ]\", \" \", sentence).split()\n",
    "        # Append the cleaned words of the sentence to the list\n",
    "        sentences.append(cleaned_sentence)\n",
    "        # Print the cleaned and split sentence\n",
    "        print(\"Processed:\", cleaned_sentence)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9ddd1",
   "metadata": {},
   "source": [
    "#### The code reads a Telugu text file, splits it into sentences, cleans each by removing non-Telugu characters (using Unicode ranges), splits them into words, and prints both the original and processed versions of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f2e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: తెలుగు భాష అందమైనది\n",
      "Processed: ['తెలుగు', 'భాష', 'అందమైనది']\n",
      "Original: ఇది భారతదేశంలో వాడబడుతున్న ఒక ప్రముఖ భాష.\n",
      "Processed: ['ఇది', 'భారతదేశంలో', 'వాడబడుతున్న', 'ఒక', 'ప్రముఖ', 'భాష']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Open the file with appropriate encoding\n",
    "file = open(\"TeluguText.txt\", \"r\", encoding='utf-8')\n",
    "# Read all lines from the file\n",
    "filedata = file.readlines()\n",
    "# Assuming the text is in the first paragraph and split into sentences by a period followed by a space\n",
    "article = re.split(r'\\.\\s+', filedata[0].strip())  # Using regex to split on '. ' for Telugu might still work\n",
    "\n",
    "sentences = []\n",
    "# Iterate over each sentence in the article\n",
    "for sentence in article:\n",
    "    if sentence.strip():  # Check if the sentence is not just whitespace\n",
    "        # Print the original sentence\n",
    "        print(\"Original:\", sentence)\n",
    "        # Clean the sentence by removing non-alphabetical characters, then split into words\n",
    "        # In Telugu, this regex will be more complex due to Unicode characters\n",
    "        cleaned_sentence = re.sub(r\"[^\\u0C00-\\u0C7F]+\", \" \", sentence).split()\n",
    "        # Append the cleaned words of the sentence to the list\n",
    "        sentences.append(cleaned_sentence)\n",
    "        # Print the cleaned and split sentence\n",
    "        print(\"Processed:\", cleaned_sentence)\n",
    "    else:\n",
    "        print(\"Skipping empty or whitespace-only sentence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070ebe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['తెలుగు', 'భాష', 'అందమైనది'], ['ఇది', 'భారతదేశంలో', 'వాడబడుతున్న', 'ఒక', 'ప్రముఖ', 'భాష']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c18f7b",
   "metadata": {},
   "source": [
    "#### The function sentence_similarity calculates the cosine similarity between two sentences by first creating frequency vectors for the words in both sentences and then computing the cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8daa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def sentence_similarity(sent1, sent2):\n",
    "    # Create a set of all words in both sentences\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "\n",
    "    # Build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "\n",
    "    # Build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "\n",
    "    # Compute cosine similarity (1 - cosine distance)\n",
    "    # Adding a small epsilon to avoid division by zero error in cosine calculation\n",
    "    cosine_similarity = 1 - cosine(vector1, vector2) if sum(vector1) and sum(vector2) else 0\n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ecfc3",
   "metadata": {},
   "source": [
    "#### The code calculates and displays a similarity matrix for a list of sentences by applying the sentence_similarity function to each pair of sentences, excluding comparisons with themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0fe8c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.23570226]\n",
      " [0.23570226 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0259303e",
   "metadata": {},
   "source": [
    "#### The code creates a graph from a similarity matrix and computes the PageRank scores for each sentence, then prints these scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c658bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.49999999999999994, 1: 0.49999999999999994}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806ccb8",
   "metadata": {},
   "source": [
    "#### The code sorts sentences based on their PageRank scores from highest to lowest and prints the ranked list, combining each sentence's score with its original text for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426f2548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.49999999999999994, ['తెలుగు', 'భాష', 'అందమైనది']), (0.49999999999999994, ['ఇది', 'భారతదేశంలో', 'వాడబడుతున్న', 'ఒక', 'ప్రముఖ', 'భాష'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8c754",
   "metadata": {},
   "source": [
    "#### The code prompts the user to specify how many top-ranked sentences to include in a summary, then constructs the summary by concatenating the specified number of highest-ranked sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17242bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0e9b6",
   "metadata": {},
   "source": [
    "#### The code outputs the final summarized text by concatenating the selected top-ranked sentences into a cohesive paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90859202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " తెలుగు భాష అందమైనది. ఇది భారతదేశంలో వాడబడుతున్న ఒక ప్రముఖ భాష\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ae774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
